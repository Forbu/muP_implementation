## muP introduction

muP parametrization transfert is a simple idea : you want to optimize your deep learning hyperparameters (learning rate, batch size, initialization etc) on small model because it's computationally cheap and then use your best found parametrization on a bigger model to avoid spending compute budget on optimizing the big model. 
